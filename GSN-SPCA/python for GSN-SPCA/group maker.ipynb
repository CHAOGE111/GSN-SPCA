{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:28:08.426379Z",
     "start_time": "2025-08-18T05:28:08.414319400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('input.csv', sep=',')\n",
    "\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "if 'IDENTIFIER' in df.columns:\n",
    "    df.set_index('IDENTIFIER', inplace=True)\n",
    "    \n",
    "\n",
    "    df_log = df.applymap(lambda x: np.log(x) if x > 0 else x)\n",
    "    \n",
    "\n",
    "    df_log.to_csv('./process document/log_data.csv')\n",
    "else:\n",
    "    print(\"Column 'IDENTIFIER' not found in the dataframe.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:17:03.530960900Z",
     "start_time": "2025-08-18T08:17:03.492438300Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing columns: 100%|██████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1006.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.45748452703425\n",
      "Data points below min_val:\n",
      " Empty DataFrame\n",
      "Columns: [A, A.1, A.2, A.3, A.4, A.5, A.6, A.7, A.8, A.9, A.10, A.11, A.12, A.13, A.14, A.15, A.16, A.17, A.18, A.19, A.20, A.21, A.22, A.23, A.24, A.25, A.26, A.27, A.28, A.29, A.30, A.31, A.32, A.33, A.34, A.35, A.36, A.37, A.38, A.39, A.40, A.41, A.42, A.43, A.44, A.45, A.46, A.47, A.48, A.49, B, B.1, B.2, B.3, B.4, B.5, B.6, B.7, B.8, B.9, B.10, B.11, B.12, B.13, B.14, B.15, B.16, B.17, B.18, B.19, B.20, B.21, B.22, B.23, B.24, B.25, B.26, B.27, B.28, B.29, B.30, B.31, B.32, B.33, B.34, B.35, B.36, B.37, B.38, B.39, B.40, B.41, B.42, B.43, B.44, B.45, B.46, B.47, B.48, B.49]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 100 columns]\n",
      "Data points above max_val:\n",
      " Empty DataFrame\n",
      "Columns: [A, A.1, A.2, A.3, A.4, A.5, A.6, A.7, A.8, A.9, A.10, A.11, A.12, A.13, A.14, A.15, A.16, A.17, A.18, A.19, A.20, A.21, A.22, A.23, A.24, A.25, A.26, A.27, A.28, A.29, A.30, A.31, A.32, A.33, A.34, A.35, A.36, A.37, A.38, A.39, A.40, A.41, A.42, A.43, A.44, A.45, A.46, A.47, A.48, A.49, B, B.1, B.2, B.3, B.4, B.5, B.6, B.7, B.8, B.9, B.10, B.11, B.12, B.13, B.14, B.15, B.16, B.17, B.18, B.19, B.20, B.21, B.22, B.23, B.24, B.25, B.26, B.27, B.28, B.29, B.30, B.31, B.32, B.33, B.34, B.35, B.36, B.37, B.38, B.39, B.40, B.41, B.42, B.43, B.44, B.45, B.46, B.47, B.48, B.49]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 100 columns]\n",
      "Discretization intervals: ['From -67.43 to -66.00 -> 1', 'From -66.00 to -64.57 -> 2', 'From -64.57 to -63.14 -> 3', 'From -63.14 to -61.71 -> 4', 'From -61.71 to -60.28 -> 5', 'From -60.28 to -58.85 -> 6', 'From -58.85 to -57.42 -> 7', 'From -57.42 to -55.99 -> 8', 'From -55.99 to -54.56 -> 9', 'From -54.56 to -53.13 -> 10', 'From -53.13 to -51.71 -> 11', 'From -51.71 to -50.28 -> 12', 'From -50.28 to -48.85 -> 13', 'From -48.85 to -47.42 -> 14', 'From -47.42 to -45.99 -> 15', 'From -45.99 to -44.56 -> 16', 'From -44.56 to -43.13 -> 17', 'From -43.13 to -41.70 -> 18', 'From -41.70 to -40.27 -> 19', 'From -40.27 to -38.84 -> 20', 'From -38.84 to -37.41 -> 21', 'From -37.41 to -35.98 -> 22', 'From -35.98 to -34.56 -> 23', 'From -34.56 to -33.13 -> 24', 'From -33.13 to -31.70 -> 25', 'From -31.70 to -30.27 -> 26', 'From -30.27 to -28.84 -> 27', 'From -28.84 to -27.41 -> 28', 'From -27.41 to -25.98 -> 29', 'From -25.98 to -24.55 -> 30', 'From -24.55 to -23.12 -> 31', 'From -23.12 to -21.69 -> 32', 'From -21.69 to -20.26 -> 33', 'From -20.26 to -18.83 -> 34', 'From -18.83 to -17.41 -> 35', 'From -17.41 to -15.98 -> 36', 'From -15.98 to -14.55 -> 37', 'From -14.55 to -13.12 -> 38', 'From -13.12 to -11.69 -> 39', 'From -11.69 to -10.26 -> 40', 'From -10.26 to -8.83 -> 41', 'From -8.83 to -7.40 -> 42', 'From -7.40 to -5.97 -> 43', 'From -5.97 to -4.54 -> 44', 'From -4.54 to -3.11 -> 45', 'From -3.11 to -1.68 -> 46', 'From -1.68 to -0.26 -> 47', 'From -0.26 to 1.17 -> 48', 'From 1.17 to 2.60 -> 49', 'From 2.60 to 4.03 -> 50']\n",
      "NaN count after discretization: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read CSV file\n",
    "df_log = pd.read_csv('./process document/log_data.csv', index_col='IDENTIFIER')\n",
    "\n",
    "# Determine global min and max values\n",
    "min_val = df_log.min().min()\n",
    "max_val = df_log.max().max()\n",
    "print(max_val - min_val)\n",
    "out_of_range_low = df_log[df_log.lt(min_val).any(axis=1)]\n",
    "out_of_range_high = df_log[df_log.gt(max_val).any(axis=1)]\n",
    "print(\"Data points below min_val:\\n\", out_of_range_low)\n",
    "print(\"Data points above max_val:\\n\", out_of_range_high)\n",
    "\n",
    "# Discretization parameters\n",
    "n = 50\n",
    "interval_width = (max_val - min_val) / n\n",
    "bins = [min_val + i * interval_width for i in range(n + 1)]\n",
    "labels = range(1, n + 1)\n",
    "\n",
    "# Define discretization function (handling floating-point precision)\n",
    "epsilon = 1e-9\n",
    "\n",
    "def discretize_value_v2(value):\n",
    "    if value != 0:\n",
    "        for i in range(n):\n",
    "            # Adjust for closed intervals with floating-point precision\n",
    "            if bins[i] - epsilon <= value <= bins[i + 1] + epsilon:\n",
    "                return labels[i]\n",
    "        return np.nan  # Return NaN if no interval matches\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Process data with progress bar\n",
    "discretized_df = pd.DataFrame(index=df_log.index)\n",
    "\n",
    "for col in tqdm(df_log.columns, desc=\"Processing columns\"):\n",
    "    # Apply updated discretization function\n",
    "    discretized_df[col] = df_log[col].map(discretize_value_v2)\n",
    "\n",
    "# Display discretization intervals\n",
    "intervals = [f\"From {bins[i]:.2f} to {bins[i + 1]:.2f} -> {labels[i]}\" for i in range(n)]\n",
    "print(\"Discretization intervals:\", intervals)\n",
    "\n",
    "# Check for NaN values after discretization\n",
    "nan_values = discretized_df.isnull().sum().sum()\n",
    "print(\"NaN count after discretization:\", nan_values)\n",
    "\n",
    "# Save discretized data to new CSV file\n",
    "discretized_df.to_csv('./process document/discretized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:35:40.863267800Z",
     "start_time": "2025-08-18T05:35:39.078188500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating metrics: 100%|██████████████████████████████████████████████████████████| 195/195 [00:00<00:00, 445.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "df_discretized = pd.read_csv('./process document/discretized_data.csv', index_col='IDENTIFIER')\n",
    "\n",
    "\n",
    "df_pairs =pd.read_csv('input.edges.txt', sep='\\t')\n",
    "\n",
    "\n",
    "def calculate_metrics(pair):\n",
    "    gene_a = pair['PARTICIPANT_A']\n",
    "    gene_b = pair['PARTICIPANT_B']\n",
    "    \n",
    "\n",
    "    if gene_a in df_discretized.index and gene_b in df_discretized.index:\n",
    "        data_a = df_discretized.loc[gene_a]\n",
    "        data_b = df_discretized.loc[gene_b]\n",
    "        \n",
    "\n",
    "        MI = mutual_info_score(data_a, data_b)\n",
    "        \n",
    "\n",
    "        values_a, counts_a = np.unique(data_a, return_counts=True)\n",
    "        probs_a = counts_a / len(data_a)\n",
    "        H_A = -np.sum(probs_a * np.log(probs_a))\n",
    "\n",
    "\n",
    "        values_b, counts_b = np.unique(data_b, return_counts=True)\n",
    "        probs_b = counts_b / len(data_b)\n",
    "        H_B = -np.sum(probs_b * np.log(probs_b))\n",
    "        \n",
    "\n",
    "        SU = 2.0 * MI / (H_A + H_B)\n",
    "        \n",
    "        return gene_a, gene_b, MI, H_A, H_B, SU\n",
    "    else:\n",
    "        return gene_a, gene_b, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "    results = list(tqdm(executor.map(calculate_metrics, df_pairs.to_dict('records')), total=len(df_pairs), desc=\"Calculating metrics\"))\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=['PARTICIPANT_A', 'PARTICIPANT_B', 'MI', 'H_A', 'H_B', 'SU'])\n",
    "\n",
    "\n",
    "df_results.to_csv('./process document/gene_pairs_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:35:47.376834600Z",
     "start_time": "2025-08-18T05:35:47.364307900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./process document/gene_pairs_analysis.csv')\n",
    "\n",
    "\n",
    "df_sorted = df.sort_values(by='SU', ascending=False)\n",
    "\n",
    "\n",
    "N = 0.1  \n",
    "df_filtered = df_sorted[df_sorted['SU'] >= N]\n",
    "\n",
    "\n",
    "df_filtered.to_csv('./process document/filtered_gene_pairs_analysis.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:36:07.464382500Z",
     "start_time": "2025-08-18T05:36:07.452878400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./process document/filtered_gene_pairs_analysis.csv')\n",
    "\n",
    "\n",
    "all_genes = pd.concat([df['PARTICIPANT_A'], df['PARTICIPANT_B']])\n",
    "edges_count = all_genes.value_counts()\n",
    "\n",
    "\n",
    "df_edges = pd.DataFrame({'Gene': edges_count.index, 'Edges': edges_count.values})\n",
    "\n",
    "\n",
    "df_edges_sorted = df_edges.sort_values(by='Edges', ascending=False)\n",
    "\n",
    "\n",
    "df_edges_sorted.to_csv('./process document/gene_edges_count_sorted.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T05:37:42.285583700Z",
     "start_time": "2025-08-18T05:37:42.238016500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "expr_df = pd.read_csv('input.csv', sep=',', index_col='IDENTIFIER')\n",
    "\n",
    "\n",
    "pairs_df = pd.read_csv('./process document/filtered_gene_pairs_analysis.csv')\n",
    "\n",
    "\n",
    "cosine_similarities = []\n",
    "\n",
    "\n",
    "for _, row in pairs_df.iterrows():\n",
    "    gene_a = row['PARTICIPANT_A']\n",
    "    gene_b = row['PARTICIPANT_B']\n",
    "    \n",
    " \n",
    "    expr_a = expr_df.loc[gene_a].values.reshape(1, -1)\n",
    "    expr_b = expr_df.loc[gene_b].values.reshape(1, -1)\n",
    "    \n",
    "   \n",
    "    cosine_sim = cosine_similarity(expr_a, expr_b)[0][0]\n",
    "    cosine_similarities.append(cosine_sim)\n",
    "\n",
    "\n",
    "pairs_df['cov'] = cosine_similarities\n",
    "\n",
    "\n",
    "pairs_df.to_csv('./process document/updated_gene_pairs.csv', index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:19:35.607877200Z",
     "start_time": "2025-08-18T08:19:33.364011800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Genes: 100%|████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm  \n",
    "\n",
    "\n",
    "gene_edges_df = pd.read_csv('./process document/gene_edges_count_sorted.csv')  \n",
    "gene_pairs_df = pd.read_csv('./process document/updated_gene_pairs.csv')  \n",
    "\n",
    "\n",
    "n = 0.1  # Threshold for filtering gene pairs\n",
    "x = 100  # Maximum iteration limit\n",
    "Q = 5    # Top Q gene pairs with highest cov selected each iteration\n",
    "W = 6    # Maximum size limit for Gene Group B set\n",
    "\n",
    "# Initialize output DataFrame\n",
    "output_df = pd.DataFrame(columns=['Iteration', 'Gene_Group_B'])\n",
    "\n",
    "# Create list of all genes\n",
    "all_genes_list = gene_edges_df['Gene'].tolist()\n",
    "\n",
    "def process_gene(gene_a):\n",
    "    # Check if gene A can form valid Gene Group B\n",
    "    potential_pairs = gene_pairs_df[(gene_pairs_df['PARTICIPANT_A'] == gene_a) | \n",
    "                                    (gene_pairs_df['PARTICIPANT_B'] == gene_a)]\n",
    "    potential_high_cov_pairs = potential_pairs[potential_pairs['cov'] > n]\n",
    "    \n",
    "    # Return empty DataFrame if no valid pairs for gene A\n",
    "    if potential_high_cov_pairs.empty:\n",
    "        return pd.DataFrame(columns=['Iteration', 'Gene_Group_B'])\n",
    "    \n",
    "    # Initialize Gene Group B set for iterations\n",
    "    gene_group_b = {gene_a}\n",
    "    \n",
    "    for _ in range(x):\n",
    "        connected_pairs = gene_pairs_df[gene_pairs_df['PARTICIPANT_A'].isin(gene_group_b) | \n",
    "                                        gene_pairs_df['PARTICIPANT_B'].isin(gene_group_b)]\n",
    "        num_connected_pairs = len(connected_pairs)\n",
    "        \n",
    "        # Select top Q highest cov pairs if exceeding threshold\n",
    "        if num_connected_pairs > Q:\n",
    "            connected_pairs = connected_pairs.sort_values(by='cov', ascending=False).head(Q)\n",
    "        \n",
    "        high_cov_pairs = connected_pairs[connected_pairs['cov'] > n]\n",
    "        \n",
    "        if high_cov_pairs.empty:\n",
    "            break\n",
    "        \n",
    "        new_genes = set(high_cov_pairs['PARTICIPANT_A']).union(set(high_cov_pairs['PARTICIPANT_B']))\n",
    "        gene_group_b.update(new_genes)\n",
    "        \n",
    "        # Stop if Gene Group B exceeds size limit\n",
    "        if len(gene_group_b) > W:\n",
    "            break\n",
    "    \n",
    "    return pd.DataFrame({'Iteration': [0], 'Gene_Group_B': [list(gene_group_b)]})\n",
    "\n",
    "# Process all genes with multithreading and progress bar\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_gene, all_genes_list), total=len(all_genes_list), desc=\"Processing Genes\"))\n",
    "\n",
    "# Combine all results into single DataFrame\n",
    "output_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Save output to CSV file\n",
    "output_df.to_csv('./process document/gene_groups_output.csv', index=False)\n",
    "\n",
    "# Save unselected genes to separate CSV file\n",
    "remaining_genes_df = pd.DataFrame({'Remaining_Genes': [gene for gene in all_genes_list if gene not in output_df['Gene_Group_B'].explode().unique()]})\n",
    "remaining_genes_df.to_csv('remaining_genes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:19:51.315027900Z",
     "start_time": "2025-08-18T08:19:51.307770300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group (3, 4, 20, 23, 27, 35, 41) has 7 gene(s).\n",
      "Group (27, 33, 35, 37, 41, 49) has 18 gene(s).\n",
      "Group (23, 27, 33, 35, 37, 41, 49) has 7 gene(s).\n",
      "Group (0, 2, 27, 33, 35, 37, 41, 49) has 8 gene(s).\n",
      "Group (8, 13, 27, 28, 35, 37, 41, 49) has 8 gene(s).\n",
      "Group (24, 27, 33, 35, 37, 41, 49) has 7 gene(s).\n",
      "Group (0, 2, 8, 13, 26, 48) has 24 gene(s).\n",
      "Group (3, 4, 23, 27, 35, 37, 41, 49) has 8 gene(s).\n",
      "Group (3, 4, 23, 27, 35, 37, 41) has 7 gene(s).\n",
      "Group (0, 2, 8, 13, 28, 35, 37, 41, 49) has 9 gene(s).\n",
      "Group (20, 27, 33, 35, 37, 41, 49) has 7 gene(s).\n",
      "Group (27, 28, 33, 35, 37, 41, 49) has 7 gene(s).\n",
      "Group (3, 4, 20, 33, 35, 37, 41, 49) has 8 gene(s).\n",
      "Group (25, 31, 36, 42, 45) has 25 gene(s).\n",
      "Group (29, 32, 39, 43, 46) has 25 gene(s).\n",
      "Group (6, 11, 15, 18, 22) has 25 gene(s).\n",
      "Group (1, 9, 12, 16, 19) has 25 gene(s).\n",
      "Group (5, 10, 14, 17, 21) has 25 gene(s).\n",
      "Group (30, 34, 40, 44, 47) has 25 gene(s).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "p =3\n",
    "\n",
    "\n",
    "df = pd.read_csv('./process document/gene_groups_output.csv')\n",
    "\n",
    "\n",
    "group_counts = {}\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    gene_group = eval(row['Gene_Group_B'])\n",
    "    \n",
    "\n",
    "    gene_count = len(gene_group)\n",
    "    \n",
    "\n",
    "    group_key = tuple(sorted(gene_group))\n",
    "    if group_key in group_counts:\n",
    "        group_counts[group_key] += gene_count\n",
    "    else:\n",
    "        group_counts[group_key] = gene_count\n",
    "\n",
    "\n",
    "filtered_group_counts = {group: count for group, count in group_counts.items() if count >= p}\n",
    "\n",
    "\n",
    "for group, count in filtered_group_counts.items():\n",
    "    print(f\"Group {group} has {count} gene(s).\")\n",
    "\n",
    "\n",
    "filtered_group_counts_df = pd.DataFrame(list(filtered_group_counts.items()), columns=['Genes', 'Gene Count'])\n",
    "filtered_group_counts_df.to_csv('./process document/filtered_gene_group_gene_counts.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T08:22:01.790603100Z",
     "start_time": "2025-08-18T08:22:01.779149900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2 subset data rows\n",
      "   Gene Count   0   1   2   3   4   5   6     7     8\n",
      "0           7   3   4  20  23  27  35  41  None  None\n",
      "1           7  23  27  33  35  37  41  49  None  None\n",
      "2           8   0   2  27  33  35  37  41    49  None\n",
      "3           8   8  13  27  28  35  37  41    49  None\n",
      "4           7  24  27  33  35  37  41  49  None  None\n",
      "Saved processed data to output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def process_data(input_file, output_file, remove_subsets=False):\n",
    "\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "\n",
    "    def split_genes(gene_string):\n",
    "        try:\n",
    "            gene_tuple = ast.literal_eval(gene_string)\n",
    "            genes = tuple(str(gene).strip(\"()'\\\"\") for gene in gene_tuple)  \n",
    "            return genes\n",
    "        except (SyntaxError, ValueError) as e:\n",
    "            print(f\"Warning: Could not parse '{gene_string}'. Error: {e}\")\n",
    "            return tuple()\n",
    "    \n",
    "\n",
    "    df['Genes'] = df['Genes'].apply(split_genes)\n",
    "    \n",
    "\n",
    "    if remove_subsets:\n",
    "        rows_to_keep = []\n",
    "        n = len(df)\n",
    "        \n",
    "        for i in range(n):\n",
    "            is_subset = False\n",
    "            genes_i = set(df.iloc[i]['Genes'])\n",
    "            \n",
    "            for j in range(n):\n",
    "                if i != j: \n",
    "                    genes_j = set(df.iloc[j]['Genes'])\n",
    "                    \n",
    "                    if genes_i.issubset(genes_j) and genes_i != genes_j:\n",
    "                        is_subset = True\n",
    "                        break\n",
    "            \n",
    "            if not is_subset:\n",
    "                rows_to_keep.append(i)\n",
    "        \n",
    "\n",
    "        df = df.iloc[rows_to_keep].reset_index(drop=True)\n",
    "        print(f\"Removed {n - len(rows_to_keep)} subset data rows\")\n",
    "    \n",
    "\n",
    "    genes_df = pd.DataFrame(df['Genes'].tolist(), index=df.index)\n",
    "    \n",
    "\n",
    "    df = pd.concat([df.drop(columns=['Genes']), genes_df], axis=1)\n",
    "    \n",
    "\n",
    "    df.columns = ['Gene Count'] + list(range(genes_df.shape[1]))\n",
    "    \n",
    "\n",
    "    print(df.head())\n",
    "    \n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved processed data to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set remove_subsets=True to enable subset removal\n",
    "    process_data('./process document/filtered_gene_group_gene_counts.csv', \n",
    "                 'output.csv', \n",
    "                 remove_subsets=True)  # Can be set to False to disable this feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
